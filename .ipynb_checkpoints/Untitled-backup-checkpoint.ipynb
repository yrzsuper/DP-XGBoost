{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd3326a",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== ['/Users/yangchengyi/Downloads/myCode/source_code/dpxgboost/lib/libxgboost.dylib']\n",
      "======== /Users/yangchengyi/opt/anaconda3/bin:/Users/yangchengyi/opt/anaconda3/condabin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/TeX/texbin:/usr/local/go/bin:/opt/X11/bin:/Library/Apple/usr/bin:/Users/yangchengyi/Downloads/myCode/source_code/dpxgboost/lib\n",
      "======== <CDLL '/Users/yangchengyi/Downloads/myCode/source_code/dpxgboost/lib/libxgboost.dylib', handle 200919120 at 0x7fec7856d5e0>\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dpxgboost as xgb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff0e841",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LD = pd.read_excel('dataset/soybean_data.xlsx', sheet_name = 0, index_col=\"Unnamed: 0\")\n",
    "LQ = pd.read_excel('dataset/soybean_data.xlsx', sheet_name = 1, index_col=\"Unnamed: 0\")\n",
    "LY = pd.read_excel('dataset/soybean_data.xlsx', sheet_name = 2, index_col=\"Unnamed: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "385bb06a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10995.440</th>\n",
       "      <th>10992.580</th>\n",
       "      <th>10989.730</th>\n",
       "      <th>10986.880</th>\n",
       "      <th>10984.030</th>\n",
       "      <th>10981.170</th>\n",
       "      <th>10978.320</th>\n",
       "      <th>10975.470</th>\n",
       "      <th>10972.620</th>\n",
       "      <th>10969.770</th>\n",
       "      <th>...</th>\n",
       "      <th>4024.529</th>\n",
       "      <th>4021.676</th>\n",
       "      <th>4018.824</th>\n",
       "      <th>4015.972</th>\n",
       "      <th>4013.120</th>\n",
       "      <th>4010.268</th>\n",
       "      <th>4007.415</th>\n",
       "      <th>4004.563</th>\n",
       "      <th>4001.711</th>\n",
       "      <th>3998.858</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LD18-54-5-1</th>\n",
       "      <td>0.293637</td>\n",
       "      <td>0.345386</td>\n",
       "      <td>0.367405</td>\n",
       "      <td>0.353483</td>\n",
       "      <td>0.332818</td>\n",
       "      <td>0.317063</td>\n",
       "      <td>0.308321</td>\n",
       "      <td>0.322031</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>0.378637</td>\n",
       "      <td>...</td>\n",
       "      <td>1.337818</td>\n",
       "      <td>1.338347</td>\n",
       "      <td>1.338074</td>\n",
       "      <td>1.337426</td>\n",
       "      <td>1.336938</td>\n",
       "      <td>1.336941</td>\n",
       "      <td>1.337450</td>\n",
       "      <td>1.338249</td>\n",
       "      <td>1.339122</td>\n",
       "      <td>1.339906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD18-54-5-2</th>\n",
       "      <td>0.273260</td>\n",
       "      <td>0.297736</td>\n",
       "      <td>0.344296</td>\n",
       "      <td>0.366579</td>\n",
       "      <td>0.351957</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.308249</td>\n",
       "      <td>0.316360</td>\n",
       "      <td>0.334786</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354339</td>\n",
       "      <td>1.355796</td>\n",
       "      <td>1.357007</td>\n",
       "      <td>1.357882</td>\n",
       "      <td>1.358525</td>\n",
       "      <td>1.359029</td>\n",
       "      <td>1.359558</td>\n",
       "      <td>1.360356</td>\n",
       "      <td>1.361438</td>\n",
       "      <td>1.362291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD18-54-5-3</th>\n",
       "      <td>0.176623</td>\n",
       "      <td>0.210188</td>\n",
       "      <td>0.262520</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>0.297286</td>\n",
       "      <td>0.284267</td>\n",
       "      <td>0.278091</td>\n",
       "      <td>0.281799</td>\n",
       "      <td>0.273696</td>\n",
       "      <td>0.240368</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352859</td>\n",
       "      <td>1.353792</td>\n",
       "      <td>1.353951</td>\n",
       "      <td>1.353440</td>\n",
       "      <td>1.353156</td>\n",
       "      <td>1.353581</td>\n",
       "      <td>1.354289</td>\n",
       "      <td>1.354846</td>\n",
       "      <td>1.355258</td>\n",
       "      <td>1.355397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD18-54-5-4</th>\n",
       "      <td>0.233919</td>\n",
       "      <td>0.291226</td>\n",
       "      <td>0.380982</td>\n",
       "      <td>0.431118</td>\n",
       "      <td>0.414464</td>\n",
       "      <td>0.365552</td>\n",
       "      <td>0.324812</td>\n",
       "      <td>0.313450</td>\n",
       "      <td>0.327986</td>\n",
       "      <td>0.349369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.347638</td>\n",
       "      <td>1.347293</td>\n",
       "      <td>1.347413</td>\n",
       "      <td>1.347813</td>\n",
       "      <td>1.348120</td>\n",
       "      <td>1.348358</td>\n",
       "      <td>1.348744</td>\n",
       "      <td>1.349305</td>\n",
       "      <td>1.349988</td>\n",
       "      <td>1.350742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD18-54-5-5</th>\n",
       "      <td>0.301912</td>\n",
       "      <td>0.331431</td>\n",
       "      <td>0.359882</td>\n",
       "      <td>0.368183</td>\n",
       "      <td>0.366175</td>\n",
       "      <td>0.356401</td>\n",
       "      <td>0.327788</td>\n",
       "      <td>0.297478</td>\n",
       "      <td>0.282435</td>\n",
       "      <td>0.272669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.362457</td>\n",
       "      <td>1.362269</td>\n",
       "      <td>1.361881</td>\n",
       "      <td>1.361440</td>\n",
       "      <td>1.361134</td>\n",
       "      <td>1.361147</td>\n",
       "      <td>1.361629</td>\n",
       "      <td>1.362615</td>\n",
       "      <td>1.363992</td>\n",
       "      <td>1.365531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LY16-54-100-6</th>\n",
       "      <td>0.413203</td>\n",
       "      <td>0.412709</td>\n",
       "      <td>0.410091</td>\n",
       "      <td>0.411389</td>\n",
       "      <td>0.419425</td>\n",
       "      <td>0.418556</td>\n",
       "      <td>0.398198</td>\n",
       "      <td>0.364432</td>\n",
       "      <td>0.330510</td>\n",
       "      <td>0.314765</td>\n",
       "      <td>...</td>\n",
       "      <td>1.435558</td>\n",
       "      <td>1.436222</td>\n",
       "      <td>1.436731</td>\n",
       "      <td>1.437057</td>\n",
       "      <td>1.437105</td>\n",
       "      <td>1.436602</td>\n",
       "      <td>1.435493</td>\n",
       "      <td>1.434473</td>\n",
       "      <td>1.434517</td>\n",
       "      <td>1.435750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LY16-54-100-7</th>\n",
       "      <td>0.313963</td>\n",
       "      <td>0.329563</td>\n",
       "      <td>0.336978</td>\n",
       "      <td>0.343901</td>\n",
       "      <td>0.364007</td>\n",
       "      <td>0.394706</td>\n",
       "      <td>0.413154</td>\n",
       "      <td>0.398632</td>\n",
       "      <td>0.359094</td>\n",
       "      <td>0.332024</td>\n",
       "      <td>...</td>\n",
       "      <td>1.440521</td>\n",
       "      <td>1.441682</td>\n",
       "      <td>1.442262</td>\n",
       "      <td>1.442013</td>\n",
       "      <td>1.441623</td>\n",
       "      <td>1.441599</td>\n",
       "      <td>1.441693</td>\n",
       "      <td>1.441574</td>\n",
       "      <td>1.441374</td>\n",
       "      <td>1.441386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LY16-54-100-8</th>\n",
       "      <td>0.323247</td>\n",
       "      <td>0.338544</td>\n",
       "      <td>0.360113</td>\n",
       "      <td>0.366485</td>\n",
       "      <td>0.355808</td>\n",
       "      <td>0.347094</td>\n",
       "      <td>0.345525</td>\n",
       "      <td>0.339544</td>\n",
       "      <td>0.329567</td>\n",
       "      <td>0.337898</td>\n",
       "      <td>...</td>\n",
       "      <td>1.441643</td>\n",
       "      <td>1.442681</td>\n",
       "      <td>1.443749</td>\n",
       "      <td>1.444302</td>\n",
       "      <td>1.444200</td>\n",
       "      <td>1.443692</td>\n",
       "      <td>1.443092</td>\n",
       "      <td>1.442613</td>\n",
       "      <td>1.442492</td>\n",
       "      <td>1.442960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LY16-54-100-9</th>\n",
       "      <td>0.445155</td>\n",
       "      <td>0.449665</td>\n",
       "      <td>0.440161</td>\n",
       "      <td>0.446256</td>\n",
       "      <td>0.476969</td>\n",
       "      <td>0.517699</td>\n",
       "      <td>0.554598</td>\n",
       "      <td>0.569118</td>\n",
       "      <td>0.533821</td>\n",
       "      <td>0.449128</td>\n",
       "      <td>...</td>\n",
       "      <td>1.438716</td>\n",
       "      <td>1.439136</td>\n",
       "      <td>1.439757</td>\n",
       "      <td>1.440553</td>\n",
       "      <td>1.441180</td>\n",
       "      <td>1.441347</td>\n",
       "      <td>1.441289</td>\n",
       "      <td>1.441401</td>\n",
       "      <td>1.441688</td>\n",
       "      <td>1.441942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LY16-54-100-10</th>\n",
       "      <td>0.383663</td>\n",
       "      <td>0.372315</td>\n",
       "      <td>0.350311</td>\n",
       "      <td>0.340593</td>\n",
       "      <td>0.353056</td>\n",
       "      <td>0.380406</td>\n",
       "      <td>0.399968</td>\n",
       "      <td>0.402498</td>\n",
       "      <td>0.403866</td>\n",
       "      <td>0.426297</td>\n",
       "      <td>...</td>\n",
       "      <td>1.429125</td>\n",
       "      <td>1.430020</td>\n",
       "      <td>1.430974</td>\n",
       "      <td>1.431481</td>\n",
       "      <td>1.431774</td>\n",
       "      <td>1.432247</td>\n",
       "      <td>1.432777</td>\n",
       "      <td>1.433050</td>\n",
       "      <td>1.433160</td>\n",
       "      <td>1.433336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 2454 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                10995.440  10992.580  10989.730  10986.880  10984.030  \\\n",
       "LD18-54-5-1      0.293637   0.345386   0.367405   0.353483   0.332818   \n",
       "LD18-54-5-2      0.273260   0.297736   0.344296   0.366579   0.351957   \n",
       "LD18-54-5-3      0.176623   0.210188   0.262520   0.295643   0.297286   \n",
       "LD18-54-5-4      0.233919   0.291226   0.380982   0.431118   0.414464   \n",
       "LD18-54-5-5      0.301912   0.331431   0.359882   0.368183   0.366175   \n",
       "...                   ...        ...        ...        ...        ...   \n",
       "LY16-54-100-6    0.413203   0.412709   0.410091   0.411389   0.419425   \n",
       "LY16-54-100-7    0.313963   0.329563   0.336978   0.343901   0.364007   \n",
       "LY16-54-100-8    0.323247   0.338544   0.360113   0.366485   0.355808   \n",
       "LY16-54-100-9    0.445155   0.449665   0.440161   0.446256   0.476969   \n",
       "LY16-54-100-10   0.383663   0.372315   0.350311   0.340593   0.353056   \n",
       "\n",
       "                10981.170  10978.320  10975.470  10972.620  10969.770  ...  \\\n",
       "LD18-54-5-1      0.317063   0.308321   0.322031   0.358805   0.378637  ...   \n",
       "LD18-54-5-2      0.324675   0.308249   0.316360   0.334786   0.331465  ...   \n",
       "LD18-54-5-3      0.284267   0.278091   0.281799   0.273696   0.240368  ...   \n",
       "LD18-54-5-4      0.365552   0.324812   0.313450   0.327986   0.349369  ...   \n",
       "LD18-54-5-5      0.356401   0.327788   0.297478   0.282435   0.272669  ...   \n",
       "...                   ...        ...        ...        ...        ...  ...   \n",
       "LY16-54-100-6    0.418556   0.398198   0.364432   0.330510   0.314765  ...   \n",
       "LY16-54-100-7    0.394706   0.413154   0.398632   0.359094   0.332024  ...   \n",
       "LY16-54-100-8    0.347094   0.345525   0.339544   0.329567   0.337898  ...   \n",
       "LY16-54-100-9    0.517699   0.554598   0.569118   0.533821   0.449128  ...   \n",
       "LY16-54-100-10   0.380406   0.399968   0.402498   0.403866   0.426297  ...   \n",
       "\n",
       "                4024.529   4021.676   4018.824   4015.972   4013.120   \\\n",
       "LD18-54-5-1      1.337818   1.338347   1.338074   1.337426   1.336938   \n",
       "LD18-54-5-2      1.354339   1.355796   1.357007   1.357882   1.358525   \n",
       "LD18-54-5-3      1.352859   1.353792   1.353951   1.353440   1.353156   \n",
       "LD18-54-5-4      1.347638   1.347293   1.347413   1.347813   1.348120   \n",
       "LD18-54-5-5      1.362457   1.362269   1.361881   1.361440   1.361134   \n",
       "...                   ...        ...        ...        ...        ...   \n",
       "LY16-54-100-6    1.435558   1.436222   1.436731   1.437057   1.437105   \n",
       "LY16-54-100-7    1.440521   1.441682   1.442262   1.442013   1.441623   \n",
       "LY16-54-100-8    1.441643   1.442681   1.443749   1.444302   1.444200   \n",
       "LY16-54-100-9    1.438716   1.439136   1.439757   1.440553   1.441180   \n",
       "LY16-54-100-10   1.429125   1.430020   1.430974   1.431481   1.431774   \n",
       "\n",
       "                4010.268   4007.415   4004.563   4001.711   3998.858   \n",
       "LD18-54-5-1      1.336941   1.337450   1.338249   1.339122   1.339906  \n",
       "LD18-54-5-2      1.359029   1.359558   1.360356   1.361438   1.362291  \n",
       "LD18-54-5-3      1.353581   1.354289   1.354846   1.355258   1.355397  \n",
       "LD18-54-5-4      1.348358   1.348744   1.349305   1.349988   1.350742  \n",
       "LD18-54-5-5      1.361147   1.361629   1.362615   1.363992   1.365531  \n",
       "...                   ...        ...        ...        ...        ...  \n",
       "LY16-54-100-6    1.436602   1.435493   1.434473   1.434517   1.435750  \n",
       "LY16-54-100-7    1.441599   1.441693   1.441574   1.441374   1.441386  \n",
       "LY16-54-100-8    1.443692   1.443092   1.442613   1.442492   1.442960  \n",
       "LY16-54-100-9    1.441347   1.441289   1.441401   1.441688   1.441942  \n",
       "LY16-54-100-10   1.432247   1.432777   1.433050   1.433160   1.433336  \n",
       "\n",
       "[308 rows x 2454 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soy_data = pd.concat([LD, LQ, LY],axis=0,sort=False)\n",
    "soy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4f205a2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels_list = soy_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc32ee4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prefix_labels_list = []\n",
    "for name in labels_list:\n",
    "    tmp_name = \"\"\n",
    "    for token in name:\n",
    "        if token.isalpha():\n",
    "            tmp_name += token\n",
    "    prefix_labels_list.append(tmp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9487b9d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prefix_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb9f5fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LD': 96, 'LQ': 101, 'LY': 111}\n"
     ]
    }
   ],
   "source": [
    "labels_counts_dict = dict()\n",
    "for name in prefix_labels_list:\n",
    "    if name in labels_counts_dict:\n",
    "        labels_counts_dict[name] += 1\n",
    "    else:\n",
    "        labels_counts_dict[name] = 1\n",
    "print(labels_counts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "215328ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "soy_data.index = prefix_labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48789bac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10995.440</th>\n",
       "      <th>10992.580</th>\n",
       "      <th>10989.730</th>\n",
       "      <th>10986.880</th>\n",
       "      <th>10984.030</th>\n",
       "      <th>10981.170</th>\n",
       "      <th>10978.320</th>\n",
       "      <th>10975.470</th>\n",
       "      <th>10972.620</th>\n",
       "      <th>10969.770</th>\n",
       "      <th>...</th>\n",
       "      <th>4024.529</th>\n",
       "      <th>4021.676</th>\n",
       "      <th>4018.824</th>\n",
       "      <th>4015.972</th>\n",
       "      <th>4013.120</th>\n",
       "      <th>4010.268</th>\n",
       "      <th>4007.415</th>\n",
       "      <th>4004.563</th>\n",
       "      <th>4001.711</th>\n",
       "      <th>3998.858</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0.293637</td>\n",
       "      <td>0.345386</td>\n",
       "      <td>0.367405</td>\n",
       "      <td>0.353483</td>\n",
       "      <td>0.332818</td>\n",
       "      <td>0.317063</td>\n",
       "      <td>0.308321</td>\n",
       "      <td>0.322031</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>0.378637</td>\n",
       "      <td>...</td>\n",
       "      <td>1.337818</td>\n",
       "      <td>1.338347</td>\n",
       "      <td>1.338074</td>\n",
       "      <td>1.337426</td>\n",
       "      <td>1.336938</td>\n",
       "      <td>1.336941</td>\n",
       "      <td>1.337450</td>\n",
       "      <td>1.338249</td>\n",
       "      <td>1.339122</td>\n",
       "      <td>1.339906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0.273260</td>\n",
       "      <td>0.297736</td>\n",
       "      <td>0.344296</td>\n",
       "      <td>0.366579</td>\n",
       "      <td>0.351957</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.308249</td>\n",
       "      <td>0.316360</td>\n",
       "      <td>0.334786</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354339</td>\n",
       "      <td>1.355796</td>\n",
       "      <td>1.357007</td>\n",
       "      <td>1.357882</td>\n",
       "      <td>1.358525</td>\n",
       "      <td>1.359029</td>\n",
       "      <td>1.359558</td>\n",
       "      <td>1.360356</td>\n",
       "      <td>1.361438</td>\n",
       "      <td>1.362291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0.176623</td>\n",
       "      <td>0.210188</td>\n",
       "      <td>0.262520</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>0.297286</td>\n",
       "      <td>0.284267</td>\n",
       "      <td>0.278091</td>\n",
       "      <td>0.281799</td>\n",
       "      <td>0.273696</td>\n",
       "      <td>0.240368</td>\n",
       "      <td>...</td>\n",
       "      <td>1.352859</td>\n",
       "      <td>1.353792</td>\n",
       "      <td>1.353951</td>\n",
       "      <td>1.353440</td>\n",
       "      <td>1.353156</td>\n",
       "      <td>1.353581</td>\n",
       "      <td>1.354289</td>\n",
       "      <td>1.354846</td>\n",
       "      <td>1.355258</td>\n",
       "      <td>1.355397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0.233919</td>\n",
       "      <td>0.291226</td>\n",
       "      <td>0.380982</td>\n",
       "      <td>0.431118</td>\n",
       "      <td>0.414464</td>\n",
       "      <td>0.365552</td>\n",
       "      <td>0.324812</td>\n",
       "      <td>0.313450</td>\n",
       "      <td>0.327986</td>\n",
       "      <td>0.349369</td>\n",
       "      <td>...</td>\n",
       "      <td>1.347638</td>\n",
       "      <td>1.347293</td>\n",
       "      <td>1.347413</td>\n",
       "      <td>1.347813</td>\n",
       "      <td>1.348120</td>\n",
       "      <td>1.348358</td>\n",
       "      <td>1.348744</td>\n",
       "      <td>1.349305</td>\n",
       "      <td>1.349988</td>\n",
       "      <td>1.350742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LD</th>\n",
       "      <td>0.301912</td>\n",
       "      <td>0.331431</td>\n",
       "      <td>0.359882</td>\n",
       "      <td>0.368183</td>\n",
       "      <td>0.366175</td>\n",
       "      <td>0.356401</td>\n",
       "      <td>0.327788</td>\n",
       "      <td>0.297478</td>\n",
       "      <td>0.282435</td>\n",
       "      <td>0.272669</td>\n",
       "      <td>...</td>\n",
       "      <td>1.362457</td>\n",
       "      <td>1.362269</td>\n",
       "      <td>1.361881</td>\n",
       "      <td>1.361440</td>\n",
       "      <td>1.361134</td>\n",
       "      <td>1.361147</td>\n",
       "      <td>1.361629</td>\n",
       "      <td>1.362615</td>\n",
       "      <td>1.363992</td>\n",
       "      <td>1.365531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LY</th>\n",
       "      <td>0.413203</td>\n",
       "      <td>0.412709</td>\n",
       "      <td>0.410091</td>\n",
       "      <td>0.411389</td>\n",
       "      <td>0.419425</td>\n",
       "      <td>0.418556</td>\n",
       "      <td>0.398198</td>\n",
       "      <td>0.364432</td>\n",
       "      <td>0.330510</td>\n",
       "      <td>0.314765</td>\n",
       "      <td>...</td>\n",
       "      <td>1.435558</td>\n",
       "      <td>1.436222</td>\n",
       "      <td>1.436731</td>\n",
       "      <td>1.437057</td>\n",
       "      <td>1.437105</td>\n",
       "      <td>1.436602</td>\n",
       "      <td>1.435493</td>\n",
       "      <td>1.434473</td>\n",
       "      <td>1.434517</td>\n",
       "      <td>1.435750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LY</th>\n",
       "      <td>0.313963</td>\n",
       "      <td>0.329563</td>\n",
       "      <td>0.336978</td>\n",
       "      <td>0.343901</td>\n",
       "      <td>0.364007</td>\n",
       "      <td>0.394706</td>\n",
       "      <td>0.413154</td>\n",
       "      <td>0.398632</td>\n",
       "      <td>0.359094</td>\n",
       "      <td>0.332024</td>\n",
       "      <td>...</td>\n",
       "      <td>1.440521</td>\n",
       "      <td>1.441682</td>\n",
       "      <td>1.442262</td>\n",
       "      <td>1.442013</td>\n",
       "      <td>1.441623</td>\n",
       "      <td>1.441599</td>\n",
       "      <td>1.441693</td>\n",
       "      <td>1.441574</td>\n",
       "      <td>1.441374</td>\n",
       "      <td>1.441386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LY</th>\n",
       "      <td>0.323247</td>\n",
       "      <td>0.338544</td>\n",
       "      <td>0.360113</td>\n",
       "      <td>0.366485</td>\n",
       "      <td>0.355808</td>\n",
       "      <td>0.347094</td>\n",
       "      <td>0.345525</td>\n",
       "      <td>0.339544</td>\n",
       "      <td>0.329567</td>\n",
       "      <td>0.337898</td>\n",
       "      <td>...</td>\n",
       "      <td>1.441643</td>\n",
       "      <td>1.442681</td>\n",
       "      <td>1.443749</td>\n",
       "      <td>1.444302</td>\n",
       "      <td>1.444200</td>\n",
       "      <td>1.443692</td>\n",
       "      <td>1.443092</td>\n",
       "      <td>1.442613</td>\n",
       "      <td>1.442492</td>\n",
       "      <td>1.442960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LY</th>\n",
       "      <td>0.445155</td>\n",
       "      <td>0.449665</td>\n",
       "      <td>0.440161</td>\n",
       "      <td>0.446256</td>\n",
       "      <td>0.476969</td>\n",
       "      <td>0.517699</td>\n",
       "      <td>0.554598</td>\n",
       "      <td>0.569118</td>\n",
       "      <td>0.533821</td>\n",
       "      <td>0.449128</td>\n",
       "      <td>...</td>\n",
       "      <td>1.438716</td>\n",
       "      <td>1.439136</td>\n",
       "      <td>1.439757</td>\n",
       "      <td>1.440553</td>\n",
       "      <td>1.441180</td>\n",
       "      <td>1.441347</td>\n",
       "      <td>1.441289</td>\n",
       "      <td>1.441401</td>\n",
       "      <td>1.441688</td>\n",
       "      <td>1.441942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LY</th>\n",
       "      <td>0.383663</td>\n",
       "      <td>0.372315</td>\n",
       "      <td>0.350311</td>\n",
       "      <td>0.340593</td>\n",
       "      <td>0.353056</td>\n",
       "      <td>0.380406</td>\n",
       "      <td>0.399968</td>\n",
       "      <td>0.402498</td>\n",
       "      <td>0.403866</td>\n",
       "      <td>0.426297</td>\n",
       "      <td>...</td>\n",
       "      <td>1.429125</td>\n",
       "      <td>1.430020</td>\n",
       "      <td>1.430974</td>\n",
       "      <td>1.431481</td>\n",
       "      <td>1.431774</td>\n",
       "      <td>1.432247</td>\n",
       "      <td>1.432777</td>\n",
       "      <td>1.433050</td>\n",
       "      <td>1.433160</td>\n",
       "      <td>1.433336</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 2454 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10995.440  10992.580  10989.730  10986.880  10984.030  10981.170  \\\n",
       "LD   0.293637   0.345386   0.367405   0.353483   0.332818   0.317063   \n",
       "LD   0.273260   0.297736   0.344296   0.366579   0.351957   0.324675   \n",
       "LD   0.176623   0.210188   0.262520   0.295643   0.297286   0.284267   \n",
       "LD   0.233919   0.291226   0.380982   0.431118   0.414464   0.365552   \n",
       "LD   0.301912   0.331431   0.359882   0.368183   0.366175   0.356401   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "LY   0.413203   0.412709   0.410091   0.411389   0.419425   0.418556   \n",
       "LY   0.313963   0.329563   0.336978   0.343901   0.364007   0.394706   \n",
       "LY   0.323247   0.338544   0.360113   0.366485   0.355808   0.347094   \n",
       "LY   0.445155   0.449665   0.440161   0.446256   0.476969   0.517699   \n",
       "LY   0.383663   0.372315   0.350311   0.340593   0.353056   0.380406   \n",
       "\n",
       "    10978.320  10975.470  10972.620  10969.770  ...  4024.529   4021.676   \\\n",
       "LD   0.308321   0.322031   0.358805   0.378637  ...   1.337818   1.338347   \n",
       "LD   0.308249   0.316360   0.334786   0.331465  ...   1.354339   1.355796   \n",
       "LD   0.278091   0.281799   0.273696   0.240368  ...   1.352859   1.353792   \n",
       "LD   0.324812   0.313450   0.327986   0.349369  ...   1.347638   1.347293   \n",
       "LD   0.327788   0.297478   0.282435   0.272669  ...   1.362457   1.362269   \n",
       "..        ...        ...        ...        ...  ...        ...        ...   \n",
       "LY   0.398198   0.364432   0.330510   0.314765  ...   1.435558   1.436222   \n",
       "LY   0.413154   0.398632   0.359094   0.332024  ...   1.440521   1.441682   \n",
       "LY   0.345525   0.339544   0.329567   0.337898  ...   1.441643   1.442681   \n",
       "LY   0.554598   0.569118   0.533821   0.449128  ...   1.438716   1.439136   \n",
       "LY   0.399968   0.402498   0.403866   0.426297  ...   1.429125   1.430020   \n",
       "\n",
       "    4018.824   4015.972   4013.120   4010.268   4007.415   4004.563   \\\n",
       "LD   1.338074   1.337426   1.336938   1.336941   1.337450   1.338249   \n",
       "LD   1.357007   1.357882   1.358525   1.359029   1.359558   1.360356   \n",
       "LD   1.353951   1.353440   1.353156   1.353581   1.354289   1.354846   \n",
       "LD   1.347413   1.347813   1.348120   1.348358   1.348744   1.349305   \n",
       "LD   1.361881   1.361440   1.361134   1.361147   1.361629   1.362615   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "LY   1.436731   1.437057   1.437105   1.436602   1.435493   1.434473   \n",
       "LY   1.442262   1.442013   1.441623   1.441599   1.441693   1.441574   \n",
       "LY   1.443749   1.444302   1.444200   1.443692   1.443092   1.442613   \n",
       "LY   1.439757   1.440553   1.441180   1.441347   1.441289   1.441401   \n",
       "LY   1.430974   1.431481   1.431774   1.432247   1.432777   1.433050   \n",
       "\n",
       "    4001.711   3998.858   \n",
       "LD   1.339122   1.339906  \n",
       "LD   1.361438   1.362291  \n",
       "LD   1.355258   1.355397  \n",
       "LD   1.349988   1.350742  \n",
       "LD   1.363992   1.365531  \n",
       "..        ...        ...  \n",
       "LY   1.434517   1.435750  \n",
       "LY   1.441374   1.441386  \n",
       "LY   1.442492   1.442960  \n",
       "LY   1.441688   1.441942  \n",
       "LY   1.433160   1.433336  \n",
       "\n",
       "[308 rows x 2454 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b318f5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = soy_data\n",
    "del soy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c91a92b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 308 entries, LD to LY\n",
      "Columns: 2454 entries, 10995.44 to 3998.858\n",
      "dtypes: float64(2454)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "062caec4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = features.fillna(features.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61e9e1fe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ed9889",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 308 entries, LD to LY\n",
      "Columns: 2454 entries, 10995.44 to 3998.858\n",
      "dtypes: float64(2454)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "773c8a40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "char2num_dict = dict()\n",
    "num = 0\n",
    "for key in labels_counts_dict:\n",
    "    char2num_dict[key] = num\n",
    "    num += 1\n",
    "del num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b5847f8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LD': 0, 'LQ': 1, 'LY': 2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2num_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f9b404e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in features.index:\n",
    "    labels.append(char2num_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b341d1c9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6689de59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features = normalize(X = features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f7f7c6b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3632784e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "rf=RandomForestClassifier(random_state=0)\n",
    "gbdt =GradientBoostingClassifier(random_state=0, n_estimators=25)\n",
    "\n",
    "clf = clf.fit(X_train,y_train)\n",
    "rf = rf.fit(X_train,y_train)\n",
    "gbdt = gbdt.fit(X_train, y_train)  # Training model\n",
    "\n",
    "score_rf =rf.score(X_test,y_test)\n",
    "score_clf =clf.score(X_test,y_test)\n",
    "score_gbdt = gbdt.score(X_test,y_test)\n",
    "\n",
    "\n",
    "print(\"决策树：\",score_clf)\n",
    "print(\"随机森林：\",score_rf)\n",
    "print(\"梯度提升树\", score_gbdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a70ecbc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 7)\n",
    "svc = SVC(kernel = 'rbf', probability=True)\n",
    "vote = VotingClassifier(estimators=[('dt', clf), \n",
    "                                    ('knn', knn), \n",
    "                                    ('svc', svc)],\n",
    "                        voting='soft', \n",
    "                        weights=[2, 1, 2]\n",
    "                       )\n",
    "\n",
    "knn = knn.fit(X_train, y_train)\n",
    "svc = svc.fit(X_train, y_train)\n",
    "vote = vote.fit(X_train, y_train)\n",
    "\n",
    "score_knn = knn.score(X_test, y_test)\n",
    "score_svc = svc.score(X_test, y_test)\n",
    "score_vote = vote.score(X_test, y_test)\n",
    "\n",
    "print(\"决策树：{}%\".format(round(score_clf*100, 1)))\n",
    "print(\"K均值{}%\".format(round(score_knn*100, 1)))\n",
    "print(\"支持向量回归{}%\".format(round(score_svc*100, 1)))\n",
    "print(\"投票集成{}%\".format(round(score_vote*100, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06dffd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58f5a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''Softmax function with x as input vector.'''\n",
    "    e = np.exp(x)\n",
    "    return e / np.sum(e)\n",
    "\n",
    "\n",
    "def softprob_obj(predt: np.ndarray, data: xgb.DMatrix):\n",
    "    '''Loss function.  Computing the gradient and approximated hessian (diagonal).\n",
    "    Reimplements the `multi:softprob` inside XGBoost.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    print('=============data===============', data.shape)\n",
    "    \n",
    "    \n",
    "    labels = data.get_label()\n",
    "    if data.get_weight().size == 0:\n",
    "        # Use 1 as weight if we don't have custom weight.\n",
    "        weights = np.ones((kRows, 1), dtype=float)\n",
    "    else:\n",
    "        weights = data.get_weight()\n",
    "\n",
    "    # The prediction is of shape (rows, classes), each element in a row\n",
    "    # represents a raw prediction (leaf weight, hasn't gone through softmax\n",
    "    # yet).  In XGBoost 1.0.0, the prediction is transformed by a softmax\n",
    "    # function, fixed in later versions.\n",
    "    assert predt.shape == (kRows, kClasses)\n",
    "\n",
    "    grad = np.zeros((kRows, kClasses), dtype=float)\n",
    "    hess = np.zeros((kRows, kClasses), dtype=float)\n",
    "\n",
    "    eps = 1e-6\n",
    "\n",
    "    # compute the gradient and hessian, slow iterations in Python, only\n",
    "    # suitable for demo.  Also the one in native XGBoost core is more robust to\n",
    "    # numeric overflow as we don't do anything to mitigate the `exp` in\n",
    "    # `softmax` here.\n",
    "    for r in range(predt.shape[0]):\n",
    "        target = labels[r]\n",
    "        p = softmax(predt[r, :])\n",
    "        for c in range(predt.shape[1]):\n",
    "            assert target >= 0 or target <= kClasses\n",
    "            g = p[c] - 1.0 if c == target else p[c]\n",
    "            g = g * weights[r]\n",
    "            h = max((2.0 * p[c] * (1.0 - p[c]) * weights[r]).item(), eps)\n",
    "            grad[r, c] = g\n",
    "            hess[r, c] = h\n",
    "\n",
    "    # Right now (XGBoost 1.0.0), reshaping is necessary\n",
    "    grad = grad.reshape((kRows * kClasses, 1))\n",
    "    hess = hess.reshape((kRows * kClasses, 1))\n",
    "    return grad, hess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02e95d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c27d3fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dpxgb = xgb.XGBClassifier(learning_rate=0.1,\n",
    "                    #n_estimatores\n",
    "                    #含义：总共迭代的次数，即决策树的个数\n",
    "                    n_estimators=1000,\n",
    "                    #max_depth\n",
    "                    #含义：树的深度，默认值为6，典型值3-10。\n",
    "                    max_depth=6,\n",
    "                    #min_child_weight\n",
    "                    #调参：值越大，越容易欠拟合；值越小，越容易过拟合\n",
    "                    #（值较大时，避免模型学习到局部的特殊样本）。\n",
    "                    min_child_weight = 1,\n",
    "                    #惩罚项系数，指定节点分裂所需的最小损失函数下降值。\n",
    "                    gamma = 0,\n",
    "                    #subsample\n",
    "                    #含义：训练每棵树时，使用的数据占全部训练集的比例。\n",
    "                    # 默认值为1，典型值为0.5-1。\n",
    "                    subsample = 0.8,\n",
    "                    #colsample_bytree\n",
    "                    #含义：训练每棵树时，使用的特征占全部特征的比例。默认值为1，典型值为0.5-1。\n",
    "                    colsample_btree = 0.8,\n",
    "                    #objective 目标函数\n",
    "                    #multi：softmax num_class=n 返回类别\n",
    "                    objective = softprob_obj,\n",
    "                    #objective = 'multi:softprob',\n",
    "                    #                     num_class= 2,\n",
    "                    #scale_pos_weight\n",
    "                    #正样本的权重，在二分类任务中，当正负样本比例失衡时，设置正样本的权重，模型效果更好。例如，当正负样本比例为1:10时，scale_pos_weight=10\n",
    "                    scale_pos_weight = 1,\n",
    "                    random_state= 27\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab40ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aecd9fdc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:21:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-37/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"colsample_btree\", \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "===========dtrain========== <class 'dpxgboost.core.DMatrix'>\n",
      "===========pred============ <class 'numpy.ndarray'>\n",
      "=============data=============== (246, 3)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wn/3vhlslcx2pjbwq10w3vvl2c40000gn/T/ipykernel_64728/1976818913.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dpxgb.fit(X_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0meval_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0meval_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mlogloss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/myCode/source_code/dpxgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/myCode/source_code/dpxgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1402\u001b[0m         )\n\u001b[1;32m   1403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m   1405\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/myCode/source_code/dpxgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/myCode/source_code/dpxgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/myCode/source_code/dpxgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1791\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===========dtrain=========='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===========pred============'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1793\u001b[0;31m             \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1794\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Differentially Privated XGBoost'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1795\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/myCode/source_code/dpxgboost/sklearn.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(preds, dmatrix)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;34m\"\"\"internal function\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wn/3vhlslcx2pjbwq10w3vvl2c40000gn/T/ipykernel_64728/3563088131.py\u001b[0m in \u001b[0;36msoftprob_obj\u001b[0;34m(predt, data)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Use 1 as weight if we don't have custom weight.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_label'"
     ]
    }
   ],
   "source": [
    "dpxgb.fit(X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        eval_metric = 'mlogloss',\n",
    "        early_stopping_rounds = 10,\n",
    "        verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd014398",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = dpxgb_cls.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"accuarcy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae6118a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2373707",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8c4cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f323d28d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e1e41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be456686",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c706bf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
